{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.9.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2041.3 MB 21 kB/s /s eta 0:00:01    |██████████                      | 641.8 MB 26.3 MB/s eta 0:00:54     |██████████████████████▉         | 1458.9 MB 17.6 MB/s eta 0:00:34\n",
      "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.2 MB 43.6 MB/s eta 0:00:01                | 563 kB 43.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio==0.9.0\n",
      "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/envs/rapids/lib/python3.7/site-packages (from torch==1.9.0+cu111) (3.10.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/rapids/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (1.20.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (8.2.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (20.9)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (4.61.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (4.5.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (2.25.1)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2021.7.6-cp37-cp37m-manylinux2014_x86_64.whl (721 kB)\n",
      "\u001b[K     |████████████████████████████████| 721 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/envs/rapids/lib/python3.7/site-packages (from huggingface-hub==0.0.12->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/rapids/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/envs/rapids/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/envs/rapids/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: regex, filelock, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.0.12 huggingface-hub-0.0.12 regex-2021.7.6 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import timeit\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    squad_convert_examples_to_features,\n",
    ")\n",
    "\n",
    "from transformers import BertForQuestionAnswering, BertConfig, BertTokenizer\n",
    "\n",
    "from transformers.data.metrics.squad_metrics import (\n",
    "    compute_predictions_log_probs,\n",
    "    compute_predictions_logits,\n",
    "    squad_evaluate,\n",
    ")\n",
    "from transformers.data.processors.squad import SquadResult, SquadV1Processor, SquadV2Processor\n",
    "from transformers.trainer_utils import is_main_process\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_QUESTION_ANSWERING_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "\n",
    "\n",
    "model_name_or_path = 'models/bert/'\n",
    "\n",
    "\n",
    "max_seq_length = 384\n",
    "doc_stride = 128\n",
    "max_query_length = 10\n",
    "threads = 12\n",
    "n_gpu = 1\n",
    "\n",
    "input_dir = \"./data/squad\"\n",
    "output_dir = \"./models/bert/\"\n",
    "model_type=\"bert\"\n",
    "# evaluate = True\n",
    "train_file = \"train-v2.0.json\"\n",
    "version_2_with_negative=True\n",
    "per_gpu_eval_batch_size=16\n",
    "\n",
    "\n",
    "n_best_size=20\n",
    "max_answer_length=30\n",
    "do_lower_case=True\n",
    "verbose_logging=True\n",
    "null_score_diff_threshold=0.0\n",
    "\n",
    "global_attention = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1\n",
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n"
     ]
    }
   ],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=0,1\n",
    "%set_env CUDA_DEVICE_ORDER=PCI_BUS_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rapids/notebooks/host\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline related parameters\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 255)) # scaler \n",
    "\n",
    "data_dir='/rapids/notebooks/host/QA_attentions_pickled'\n",
    "representation_dir='/rapids/notebooks/host/QA_attentions_pickled/representations'\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x    \n",
    "    \n",
    "representation_model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
    "representation_model.fc = Identity() # pass through values from second to last layer, bypassing linear classifier\n",
    "\n",
    "device = \"cuda:1\"\n",
    "cuda = torch.device('cuda:1')\n",
    "representation_model.to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline methods\n",
    "\n",
    "def plot_layer_heads(attention, num_layers=12, num_heads=12):\n",
    "  for i in range(0,11):\n",
    "    p = attention[i]\n",
    "    fig, axis = plt.subplots(1,12, figsize=(20,5), facecolor='w', edgecolor='k')\n",
    "    plt.title(f'layer {i}')\n",
    "    head = 0\n",
    "    for axs, ph in zip(axis.flatten(), p):\n",
    "      heatmap = axs.imshow(ph, cmap='hot')\n",
    "    \n",
    "def scale_examples(examples):\n",
    "    num_examples = len(examples)\n",
    "    scaled_examples = np.empty(shape=(num_examples), dtype=np.ndarray)\n",
    "    for i, example in enumerate(examples):\n",
    "        new_example = np.empty(shape=(12,12), dtype=np.ndarray)\n",
    "        for l, layer in enumerate(example): #12 layers\n",
    "            new_layer = np.array([])\n",
    "            for h, head in enumerate(layer): #12 heads\n",
    "                flat_head_transformed = scaler.fit_transform(head)\n",
    "                new_example[l,h] = flat_head_transformed.reshape(384,384)\n",
    "        scaled_examples[i] = new_example\n",
    "    return scaled_examples\n",
    "\n",
    "# create (1, 3, 384, 384) shape expected by barlow twins model\n",
    "def reshape_example(image):\n",
    "    example_channel = np.expand_dims(image, axis=0)\n",
    "    batch = np.append(example_channel, example_channel, axis=0)\n",
    "    batch = np.append(batch, example_channel, axis=0)\n",
    "    example_3channel = np.expand_dims(batch, axis=0)\n",
    "    return example_3channel\n",
    "\n",
    "def get_representations(attentions):\n",
    "    num_attentions = len(attentions)\n",
    "    barlow_representations = np.zeros((num_attentions), np.object)\n",
    "    for i, example in enumerate(attentions):\n",
    "        reshaped_example = np.zeros((12,12), np.object)\n",
    "        for l, layer in enumerate(example):\n",
    "            for h, head in enumerate(layer):\n",
    "                reshaped_head = torch.from_numpy(reshape_example(head)).to(cuda)\n",
    "                representation_head = representation_model(reshaped_head.float())\n",
    "                reshaped_example[l][h] = representation_head.detach().cpu().numpy()\n",
    "        barlow_representations[i] = reshaped_example\n",
    "\n",
    "    return barlow_representations\n",
    "\n",
    "def flatten_layer_heads(representations_tensor):\n",
    "    print(\"flattening layers/heads ...\")\n",
    "    num_examples =  len(representations_tensor)\n",
    "    flat_array = np.zeros((num_examples * 12 * 12), np.ndarray)\n",
    "    i = 0\n",
    "    for example in representations_tensor:\n",
    "        for layer in example:\n",
    "            for h, head in enumerate(layer):\n",
    "                flat_array[i] = head[0]\n",
    "                i += 1\n",
    "    return flat_array\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 100\n",
    "# batch_num = 0\n",
    "# representation_df = pd.DataFrame()\n",
    "# representation_array = []\n",
    "# for i in range(1,21):\n",
    "#     start_time = time.time()\n",
    "#     batch_num = i * batch_size\n",
    "#     print(f\"Loading attentions batch {batch_num}\")\n",
    "#     attentions = torch.load(os.path.join(data_dir, f\"eval_attentions_{batch_num}.bin\"))\n",
    "#     print(\"Scaling attention values to 0-255 ...\")\n",
    "#     scaled_attentions =  scale_examples(attentions)\n",
    "#     print(\"Processing to 2048 value representations through barlow_twins ...\")\n",
    "#     barlow_representations = get_representations(scaled_attentions)\n",
    "#     print(\"Appending results to array/dataframe ...\")\n",
    "#     flat_representations = flatten_layer_heads(barlow_representations)\n",
    "#     representation_array.append(flat_representations)\n",
    "#     df = pd.DataFrame(flat_representations)\n",
    "#     df = pd.DataFrame([pd.Series(x) for x in df[0]])\n",
    "#     representation_df = representation_df.append(df, ignore_index=True)\n",
    "#     print(f\"--- eval to representation batch {batch_num} in  {(time.time() - start_time)} seconds ---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset, examples, features = load_and_cache_examples({'data_dir': \"\"}, tokenizer, evaluate=True, output_examples=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset = torch.utils.data.Subset(dataset, range(40000, 131944))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()\n",
    "\n",
    "def evaluate(args, model, tokenizer, prefix=\"\"):\n",
    "    dataset, examples, features = load_and_cache_examples(args, tokenizer, evaluate=True, output_examples=True)\n",
    "\n",
    "#     if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
    "#         os.makedirs(args.output_dir)\n",
    "\n",
    "    eval_batch_size = 1 * max(1, n_gpu)\n",
    "\n",
    "    subset = torch.utils.data.Subset(dataset, range(130000, 131944))\n",
    "\n",
    "    eval_sampler = SequentialSampler(subset)\n",
    "    eval_dataloader = DataLoader(subset, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "    \n",
    "#     eval_sampler = SequentialSampler(dataset)\n",
    "#     eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "\n",
    "    # multi-gpu evaluate\n",
    "    if n_gpu > 1 and not isinstance(model, torch.nn.DataParallel):\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "#     logger.info(\"  Num examples = %d\", len(dataset))\n",
    "    logger.info(\"  Num examples = %d\", len(subset))\n",
    "    logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "\n",
    "    all_results = []\n",
    "    all_attentions = []\n",
    "    start_time = timeit.default_timer()\n",
    "    attn_count = 130000\n",
    "\n",
    "    representation_df = pd.DataFrame()\n",
    "    \n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2],\n",
    "            }\n",
    "\n",
    "            if model_type in [\"xlm\", \"roberta\", \"distilbert\", \"camembert\", \"bart\", \"longformer\"]:\n",
    "                del inputs[\"token_type_ids\"]\n",
    "\n",
    "            feature_indices = batch[3]\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        for i, feature_index in enumerate(feature_indices):\n",
    "            eval_feature = features[feature_index.item()]\n",
    "            unique_id = int(eval_feature.unique_id)\n",
    "\n",
    "            start_logits = outputs.start_logits\n",
    "            end_logits = outputs.end_logits\n",
    "            attentions = get_layers(outputs.attentions)\n",
    "\n",
    "            result = SquadResult(unique_id, start_logits, end_logits)\n",
    "            all_results.append(result)\n",
    "\n",
    "#             append_list_as_row('QA_bert_attentions.csv', attentions)\n",
    "            all_attentions.append(attentions)\n",
    "\n",
    "    \n",
    "            attn_count += 1\n",
    "            if attn_count % 250 == 0:\n",
    "#                 representation_array = []\n",
    "#                 for i, attentions in enumerate(all_attentions):\n",
    "                logger.info(\"Scaling attention values to 0-255 ...\")\n",
    "                representations = scale_examples(all_attentions)\n",
    "                logger.info(\"Processing to 2048 value representations through barlow_twins ...\")\n",
    "                representations = get_representations(representations)\n",
    "                logger.info(\"Appending results to array/dataframe ...\")\n",
    "                representations = flatten_layer_heads(representations)\n",
    "#                 representation_array.append(flat_representations)\n",
    "                df = pd.DataFrame(representations)\n",
    "                df = pd.DataFrame([pd.Series(x) for x in df[0]])\n",
    "                representation_df = representation_df.append(df, ignore_index=True)\n",
    "#                 logger.info(\"  Outputting Attention File %s eval_attentions %i\", output_dir, attn_count)\n",
    "#                 torch.save(all_attentions, \"QA_attentions_pickled/eval_attentions_\" +str(attn_count)+\".bin\")\n",
    "#                 representation_df.to_csv(os.path.join(data_dir, f\"representation_df_{attn_count}.csv\"))\n",
    "                print(f\"--- eval to representation batch {attn_count} ---\")          \n",
    "                all_attentions = []\n",
    "                representations = []\n",
    "                df = pd.DataFrame()\n",
    "            \n",
    "            if attn_count % 5000 == 0 or attn_count == 131944:\n",
    "                logger.info(f\"  Outputting Attention File representation_df_{attn_count} to {representation_dir}\")\n",
    "                representation_df.to_csv(os.path.join(representation_dir, f\"representation_df_{attn_count}.csv\"))\n",
    "                representation_df = pd.DataFrame()\n",
    "\n",
    "    evalTime = timeit.default_timer() - start_time\n",
    "    logger.info(\"  Evaluation done in total %f secs (%f sec per example)\", evalTime, evalTime / len(dataset))\n",
    "#     global_attention = all_attentions\n",
    "#     logger.info(\"  Outputting Attention File %s eval_attentions.bin\", output_dir)\n",
    "#     torch.save(all_attentions, os.path.join(output_dir, \"eval_attentions.bin\"))\n",
    "    \n",
    "\n",
    "    \n",
    "#     with open(os.path.join(output_dir, \"eval_attentions.pkl\"), 'wb') as attention_file:\n",
    "#       pickle.dump(all_attentions, attention_file)\n",
    "\n",
    "    # Compute predictions\n",
    "#     output_prediction_file = os.path.join(output_dir, \"predictions_{}.json\".format(prefix))\n",
    "#     output_nbest_file = os.path.join(output_dir, \"nbest_predictions_{}.json\".format(prefix))\n",
    "\n",
    "#     if version_2_with_negative:\n",
    "#         output_null_log_odds_file = os.path.join(output_dir, \"null_odds_{}.json\".format(prefix))\n",
    "#     else:\n",
    "#         output_null_log_odds_file = None\n",
    "\n",
    "#     # XLNet and XLM use a more complex post-processing procedure\n",
    "#     if args.model_type in [\"xlnet\", \"xlm\"]:\n",
    "#         start_n_top = model.config.start_n_top if hasattr(model, \"config\") else model.module.config.start_n_top\n",
    "#         end_n_top = model.config.end_n_top if hasattr(model, \"config\") else model.module.config.end_n_top\n",
    "\n",
    "#         predictions = compute_predictions_log_probs(\n",
    "#             examples,\n",
    "#             features,\n",
    "#             all_results,\n",
    "#             args.n_best_size,\n",
    "#             args.max_answer_length,\n",
    "#             output_prediction_file,\n",
    "#             output_nbest_file,\n",
    "#             output_null_log_odds_file,\n",
    "#             start_n_top,\n",
    "#             end_n_top,\n",
    "#             args.version_2_with_negative,\n",
    "#             tokenizer,\n",
    "#             args.verbose_logging,\n",
    "#         )\n",
    "#     else:\n",
    "#         predictions = compute_predictions_logits(\n",
    "#             examples,\n",
    "#             features,\n",
    "#             all_results,\n",
    "#             n_best_size,\n",
    "#             max_answer_length,\n",
    "#             do_lower_case,\n",
    "#             output_prediction_file,\n",
    "#             output_nbest_file,\n",
    "#             output_null_log_odds_file,\n",
    "#             verbose_logging,\n",
    "#             version_2_with_negative,\n",
    "#             null_score_diff_threshold,\n",
    "#             tokenizer,\n",
    "#         )\n",
    "\n",
    "#     # Compute the F1 and exact scores.\n",
    "#     results = squad_evaluate(examples, predictions)\n",
    "#     return results\n",
    "\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(attention, num_layers=12, num_heads=12):\n",
    "  layers = np.ndarray((num_heads,num_layers), np.ndarray)\n",
    "  for i, layer in enumerate(attention):\n",
    "    layer = layer.detach().cpu().numpy()[0]\n",
    "    for j, head in enumerate(layer):\n",
    "      layers[i,j] = head\n",
    "  return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from csv import writer\n",
    "def append_list_as_row(file_name, list_of_elem):\n",
    "    # Open file in append mode\n",
    "    with open(file_name, 'a+', newline='') as write_obj:\n",
    "        # Create a writer object from csv module\n",
    "        csv_writer = writer(write_obj)\n",
    "        # Add contents of list as last row in the csv file\n",
    "        csv_writer.writerow(list_of_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_and_cache_examples(args, tokenizer, evaluate=False, output_examples=False):\n",
    "    # Load data features from cache or dataset file\n",
    "#     input_dir = data_dir else \".\"\n",
    "\n",
    "    cached_features_file = os.path.join(\n",
    "        input_dir,\n",
    "        \"cached_{}_{}_{}\".format(\n",
    "            \"train\",\n",
    "            list(filter(None, model_name_or_path.split(\"/\"))).pop(),\n",
    "            str(max_seq_length),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    logger.info(\"cached features file: %s\", cached_features_file)\n",
    "#     Init features and dataset from cache if it exists\n",
    "    if os.path.exists(cached_features_file):\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features_and_dataset = torch.load(cached_features_file)\n",
    "        features, dataset, examples = (\n",
    "            features_and_dataset[\"features\"],\n",
    "            features_and_dataset[\"dataset\"],\n",
    "            features_and_dataset[\"examples\"],\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", input_dir)\n",
    "\n",
    "        examples = processor.get_train_examples(input_dir, filename=train_file)\n",
    "\n",
    "        logger.info(\"Got features from dataset file at %s\", input_dir)\n",
    "\n",
    "        features, dataset = squad_convert_examples_to_features(\n",
    "            examples=examples,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_length=max_seq_length,\n",
    "            doc_stride=doc_stride,\n",
    "            max_query_length=max_query_length,\n",
    "            is_training=False,\n",
    "            return_dataset=\"pt\",\n",
    "            threads=threads,\n",
    "        )\n",
    "\n",
    "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "        torch.save({\"features\": features, \"dataset\": dataset, \"examples\": examples}, cached_features_file)\n",
    "\n",
    "    if output_examples:\n",
    "        return dataset, examples, features\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2021 04:44:51 - WARNING - __main__ -   device: cuda:1, n_gpu: 1\n",
      "[INFO|configuration_utils.py:528] 2021-07-17 04:44:52,001 >> loading configuration file models/bert/config.json\n",
      "[INFO|configuration_utils.py:566] 2021-07-17 04:44:52,003 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1651] 2021-07-17 04:44:52,005 >> Didn't find file models/bert/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1651] 2021-07-17 04:44:52,006 >> Didn't find file models/bert/tokenizer.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1715] 2021-07-17 04:44:52,007 >> loading file models/bert/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1715] 2021-07-17 04:44:52,007 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1715] 2021-07-17 04:44:52,008 >> loading file models/bert/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1715] 2021-07-17 04:44:52,008 >> loading file models/bert/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1715] 2021-07-17 04:44:52,009 >> loading file None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger.warning(\n",
    "    \"device: %s, n_gpu: %s\",\n",
    "    device,\n",
    "    n_gpu\n",
    ")\n",
    "# Set the verbosity to info of the Transformers logger (on main process only):\n",
    "# if is_main_process(args.local_rank):\n",
    "transformers.utils.logging.set_verbosity_info()\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "# Set seed\n",
    "set_seed(42)\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "config = BertConfig.from_pretrained(model_name_or_path, output_attentions=True) # no config_path?\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    do_lower_case=True,\n",
    "    cache_dir=input_dir,\n",
    "    use_fast=False,  # SquadDataset is not compatible with Fast tokenizers which have a smarter overflow handeling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:528] 2021-07-17 04:44:52,126 >> loading configuration file models/bert/config.json\n",
      "[INFO|configuration_utils.py:566] 2021-07-17 04:44:52,127 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1159] 2021-07-17 04:44:52,127 >> loading weights file models/bert/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1345] 2021-07-17 04:44:53,744 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1354] 2021-07-17 04:44:53,745 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at models/bert/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "07/17/2021 04:44:53 - INFO - __main__ -   cached features file: ./data/squad/cached_train_bert_384\n",
      "07/17/2021 04:44:53 - INFO - __main__ -   Loading features from cached file ./data/squad/cached_train_bert_384\n",
      "07/17/2021 04:46:38 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "07/17/2021 04:46:38 - INFO - __main__ -     Num examples = 1944\n",
      "07/17/2021 04:46:38 - INFO - __main__ -     Batch size = 1\n",
      "Evaluating:  13%|█▎        | 249/1944 [00:13<01:32, 18.39it/s]07/17/2021 04:46:51 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:  13%|█▎        | 249/1944 [00:29<01:32, 18.39it/s]07/17/2021 04:47:24 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "07/17/2021 04:54:24 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  13%|█▎        | 254/1944 [07:56<19:06:11, 40.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 130250 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  26%|██▌       | 499/1944 [08:02<00:33, 43.03it/s]   07/17/2021 04:54:40 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:  26%|██▌       | 499/1944 [08:20<00:33, 43.03it/s]07/17/2021 04:55:06 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/17/2021 05:01:56 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  26%|██▌       | 504/1944 [15:25<9:39:50, 24.16s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 130500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  39%|███▊      | 749/1944 [15:31<00:27, 43.03it/s]  07/17/2021 05:02:09 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:  39%|███▊      | 749/1944 [15:50<00:27, 43.03it/s]07/17/2021 05:02:36 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/17/2021 05:09:28 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  39%|███▉      | 755/1944 [23:00<7:29:31, 22.68s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 130750 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  51%|█████     | 995/1944 [23:06<00:22, 42.96it/s]  07/17/2021 05:09:44 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:  51%|█████     | 995/1944 [23:20<00:22, 42.96it/s]07/17/2021 05:10:10 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/17/2021 05:17:02 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  52%|█████▏    | 1004/1944 [30:32<5:12:18, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 131000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  64%|██████▍   | 1249/1944 [30:37<00:16, 43.11it/s]  07/17/2021 05:17:15 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:  64%|██████▍   | 1249/1944 [30:50<00:16, 43.11it/s]07/17/2021 05:17:42 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/17/2021 05:24:49 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  65%|██████▍   | 1254/1944 [38:21<4:50:29, 25.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 131250 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  77%|███████▋  | 1499/1944 [38:27<00:10, 43.33it/s]  07/17/2021 05:25:05 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:  77%|███████▋  | 1499/1944 [38:42<00:10, 43.33it/s]07/17/2021 05:25:31 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/17/2021 05:32:21 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  77%|███████▋  | 1505/1944 [45:50<2:43:46, 22.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 131500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  90%|████████▉ | 1745/1944 [45:56<00:04, 43.31it/s]  07/17/2021 05:32:34 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:  90%|████████▉ | 1745/1944 [46:12<00:04, 43.31it/s]07/17/2021 05:33:00 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/17/2021 05:39:53 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  90%|█████████ | 1755/1944 [53:25<59:29, 18.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 131750 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████▉| 1940/1944 [53:29<00:00, 43.19it/s]07/17/2021 05:40:07 - INFO - __main__ -     Outputting Attention File representation_df_131944 to /rapids/notebooks/host/QA_attentions_pickled/representations\n",
      "Evaluating: 100%|██████████| 1944/1944 [1:01:43<00:00,  1.90s/it]\n",
      "07/17/2021 05:48:21 - INFO - __main__ -     Evaluation done in total 3703.045666 secs (0.028065 sec per example)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8a262ffbf045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#model = AutoModelForQuestionAnswering.from_pretrained(model_name_or_path, output_attentions=True)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name_or_path, output_attentions=True)\n",
    "device = \"cuda:1\"\n",
    "model = model.to(device)\n",
    "# Evaluate\n",
    "processor = SquadV2Processor() if version_2_with_negative else SquadV1Processor()\n",
    "result = evaluate({'data_dir': \"\"}, model, tokenizer)\n",
    "\n",
    "result = dict((k + (\"_{}\".format(global_step) if global_step else \"\"), v) for k, v in result.items())\n",
    "results.update(result)\n",
    "\n",
    "logger.info(\"Results: {}\".format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrr = [0.03609005,0.02730089,0.01784932,0.00970263,0.03209871,0.02975531,0.01899219,0.0159386,0.09006939,0.00353505,0.00430149,0.00373916,0.004033,0.0054037,0.00314571,0.00544514,0.00577388,0.00909712,0.00366947,0.00779078,0.0060854,0.00374152,0.00431431,0.00433876,0.00607211,0.00415887,0.00477201,0.00399395,0.00448466,0.00406087,0.00554479,0.00403477,0.00403658,0.00570019,0.00253348,0.00786278,0.00268425,0.00286821,0.00445756,0.00259511,0.01361431,0.00179666,0.00279525,0.00253426,0.00443048,0.00275498,0.00693157,0.00444886,0.00678853,0.00411692,0.0071019,0.00660669,0.00816385,0.00570161,0.00614765,0.00302077,0.00278247,0.00188732,0.00286246,0.00246164,0.00384467,0.00554711,0.00819303,0.00627691,0.00650617,0.00496393,0.00559988,0.00612233,0.01119899,0.00860447,0.00352704,0.0071039,0.00396436,0.00965003,0.00511713,0.00618074,0.00690801,0.00618426,0.0035491,0.00724508,0.00985016,0.00404688,0.00427996,0.00285223,0.00245299,0.00591965,0.00313316,0.00378624,0.00741692,0.00399197,0.00309289,0.00225511,0.00550424,0.00611447,0.00585844,0.00925419,0.00312216,0.00596423,0.00268668,0.0018134,0.00285068,0.00261073,0.00597714,0.00725985,0.00449176,0.01075981,0.00320032,0.00597627,0.00291104,0.00275812,0.00203771,0.00306792,0.00339498,0.00513527,0.00229073,0.00349129,0.00306995,0.00403183,0.00349238,0.00516681,0.00469688,0.00314611,0.00399399,0.00605243,0.00566731,0.00388196,0.00273817,0.00305755,0.00224174,0.00391221,0.00251756,0.00190409,0.00828339,0.00398148,0.00303265,0.00302295,0.00196971,0.00284096,0.00145757,0.00371954,0.00356667,0.00184108,0.0033674,0.00493111,0.00370861,0.00118721,0.00130349,0.00143106,0.00201871,0.00370352,0.00239526,0.00200266,0.00348562,0.00141907,0.00355505,0.00185585,0.00149471,0.002439,0.00457984,0.00260334,0.00734435,0.00277519,0.0014447,,0.00187251,0.00321797,0.00269519,0.00156433,0.0038524,0.00148884,0.00231959,0.00253542,0.00174283,0.00346243,0.01599906,\n",
    "0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
