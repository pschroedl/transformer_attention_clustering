{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.9.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2041.3 MB 21 kB/s s eta 0:00:01    |██████▏                         | 395.3 MB 4.8 MB/s eta 0:05:46     |██████▎                         | 400.3 MB 4.8 MB/s eta 0:05:45     |█████████                       | 574.0 MB 4.9 MB/s eta 0:04:58     |█████████████▏                  | 842.4 MB 27.6 MB/s eta 0:00:44     |██████████████▏                 | 905.8 MB 25.5 MB/s eta 0:00:45     |████████████████▌               | 1049.8 MB 8.4 MB/s eta 0:01:58     |█████████████████████▋          | 1380.9 MB 19.1 MB/s eta 0:00:35     |██████████████████████▋         | 1442.6 MB 9.0 MB/s eta 0:01:07     |████████████████████████▍       | 1556.6 MB 19.9 MB/s eta 0:00:25\n",
      "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.2 MB 2.6 MB/s eta 0:00:011   |███████████                     | 7.9 MB 821 kB/s eta 0:00:19\n",
      "\u001b[?25hCollecting torchaudio==0.9.0\n",
      "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/envs/rapids/lib/python3.7/site-packages (from torch==1.9.0+cu111) (3.10.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/rapids/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (1.20.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (8.2.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.1+cu111\n",
      "    Uninstalling torch-1.8.1+cu111:\n",
      "      Successfully uninstalled torch-1.8.1+cu111\n",
      "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/envs/rapids/lib/python3.7/site-packages (4.8.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (2021.7.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (4.61.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (4.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/rapids/lib/python3.7/site-packages (from huggingface-hub==0.0.12->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: six in /opt/conda/envs/rapids/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/envs/rapids/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/rapids/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import timeit\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    squad_convert_examples_to_features,\n",
    ")\n",
    "\n",
    "from transformers import BertForQuestionAnswering, BertConfig, BertTokenizer\n",
    "\n",
    "from transformers.data.metrics.squad_metrics import (\n",
    "    compute_predictions_log_probs,\n",
    "    compute_predictions_logits,\n",
    "    squad_evaluate,\n",
    ")\n",
    "from transformers.data.processors.squad import SquadResult, SquadV1Processor, SquadV2Processor\n",
    "from transformers.trainer_utils import is_main_process\n",
    "\n",
    "\n",
    "# try:\n",
    "#     from torch.utils.tensorboard import SummaryWriter\n",
    "# except ImportError:\n",
    "#     from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_QUESTION_ANSWERING_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "\n",
    "\n",
    "model_name_or_path = 'models/bert/'\n",
    "# cache_dir=cache_dir = 'models/cache'\n",
    "\n",
    "max_seq_length = 384\n",
    "doc_stride = 128\n",
    "max_query_length = 10\n",
    "threads = 12\n",
    "n_gpu = 1\n",
    "\n",
    "input_dir = \"./data/squad\"\n",
    "output_dir = \"./models/bert/\"\n",
    "model_type=\"bert\"\n",
    "# evaluate = True\n",
    "train_file = \"train-v2.0.json\"\n",
    "version_2_with_negative=True\n",
    "per_gpu_eval_batch_size=16\n",
    "\n",
    "\n",
    "n_best_size=20\n",
    "max_answer_length=30\n",
    "do_lower_case=True\n",
    "verbose_logging=True\n",
    "null_score_diff_threshold=0.0\n",
    "\n",
    "global_attention = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1\n",
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n"
     ]
    }
   ],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=0,1\n",
    "%set_env CUDA_DEVICE_ORDER=PCI_BUS_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rapids/notebooks/host\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline related parameters\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 255)) # scaler \n",
    "\n",
    "data_dir='/rapids/notebooks/host/QA_attentions_pickled'\n",
    "representation_dir='/rapids/notebooks/host/QA_attentions_pickled/representations'\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x    \n",
    "    \n",
    "representation_model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
    "representation_model.fc = Identity() # pass through values from second to last layer, bypassing linear classifier\n",
    "\n",
    "device = \"cuda:1\"\n",
    "cuda = torch.device('cuda:1')\n",
    "representation_model.to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline methods\n",
    "\n",
    "def plot_layer_heads(attention, num_layers=12, num_heads=12):\n",
    "  for i in range(0,11):\n",
    "    p = attention[i]\n",
    "    fig, axis = plt.subplots(1,12, figsize=(20,5), facecolor='w', edgecolor='k')\n",
    "    plt.title(f'layer {i}')\n",
    "    head = 0\n",
    "    for axs, ph in zip(axis.flatten(), p):\n",
    "      heatmap = axs.imshow(ph, cmap='hot')\n",
    "    \n",
    "def scale_examples(examples):\n",
    "    num_examples = len(examples)\n",
    "    scaled_examples = np.empty(shape=(num_examples), dtype=np.ndarray)\n",
    "    for i, example in enumerate(examples):\n",
    "        new_example = np.empty(shape=(12,12), dtype=np.ndarray)\n",
    "        for l, layer in enumerate(example): #12 layers\n",
    "            new_layer = np.array([])\n",
    "            for h, head in enumerate(layer): #12 heads\n",
    "                flat_head_transformed = scaler.fit_transform(head)\n",
    "                new_example[l,h] = flat_head_transformed.reshape(384,384)\n",
    "        scaled_examples[i] = new_example\n",
    "    return scaled_examples\n",
    "\n",
    "# create (1, 3, 384, 384) shape expected by barlow twins model\n",
    "def reshape_example(image):\n",
    "    example_channel = np.expand_dims(image, axis=0)\n",
    "    batch = np.append(example_channel, example_channel, axis=0)\n",
    "    batch = np.append(batch, example_channel, axis=0)\n",
    "    example_3channel = np.expand_dims(batch, axis=0)\n",
    "    return example_3channel\n",
    "\n",
    "def get_representations(attentions):\n",
    "    num_attentions = len(attentions)\n",
    "    barlow_representations = np.zeros((num_attentions), np.object)\n",
    "    for i, example in enumerate(attentions):\n",
    "        reshaped_example = np.zeros((12,12), np.object)\n",
    "        for l, layer in enumerate(example):\n",
    "            for h, head in enumerate(layer):\n",
    "                reshaped_head = torch.from_numpy(reshape_example(head)).to(cuda)\n",
    "                representation_head = representation_model(reshaped_head.float())\n",
    "                reshaped_example[l][h] = representation_head.detach().cpu().numpy()\n",
    "        barlow_representations[i] = reshaped_example\n",
    "\n",
    "    return barlow_representations\n",
    "\n",
    "def flatten_layer_heads(representations_tensor):\n",
    "    print(\"flattening layers/heads ...\")\n",
    "    num_examples =  len(representations_tensor)\n",
    "    flat_array = np.zeros((num_examples * 12 * 12), np.ndarray)\n",
    "    i = 0\n",
    "    for example in representations_tensor:\n",
    "        for layer in example:\n",
    "            for h, head in enumerate(layer):\n",
    "                flat_array[i] = head[0]\n",
    "                i += 1\n",
    "    return flat_array\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 100\n",
    "# batch_num = 0\n",
    "# representation_df = pd.DataFrame()\n",
    "# representation_array = []\n",
    "# for i in range(1,21):\n",
    "#     start_time = time.time()\n",
    "#     batch_num = i * batch_size\n",
    "#     print(f\"Loading attentions batch {batch_num}\")\n",
    "#     attentions = torch.load(os.path.join(data_dir, f\"eval_attentions_{batch_num}.bin\"))\n",
    "#     print(\"Scaling attention values to 0-255 ...\")\n",
    "#     scaled_attentions =  scale_examples(attentions)\n",
    "#     print(\"Processing to 2048 value representations through barlow_twins ...\")\n",
    "#     barlow_representations = get_representations(scaled_attentions)\n",
    "#     print(\"Appending results to array/dataframe ...\")\n",
    "#     flat_representations = flatten_layer_heads(barlow_representations)\n",
    "#     representation_array.append(flat_representations)\n",
    "#     df = pd.DataFrame(flat_representations)\n",
    "#     df = pd.DataFrame([pd.Series(x) for x in df[0]])\n",
    "#     representation_df = representation_df.append(df, ignore_index=True)\n",
    "#     print(f\"--- eval to representation batch {batch_num} in  {(time.time() - start_time)} seconds ---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()\n",
    "\n",
    "def evaluate(args, model, tokenizer, prefix=\"\"):\n",
    "    dataset, examples, features = load_and_cache_examples(args, tokenizer, evaluate=True, output_examples=True)\n",
    "\n",
    "#     if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
    "#         os.makedirs(args.output_dir)\n",
    "\n",
    "    eval_batch_size = 1 * max(1, n_gpu)\n",
    "\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(dataset)\n",
    "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "\n",
    "    # multi-gpu evaluate\n",
    "    if n_gpu > 1 and not isinstance(model, torch.nn.DataParallel):\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(dataset))\n",
    "    logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "\n",
    "    all_results = []\n",
    "    all_attentions = []\n",
    "    start_time = timeit.default_timer()\n",
    "    attn_count = 0\n",
    "\n",
    "    representation_df = pd.DataFrame()\n",
    "    \n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2],\n",
    "            }\n",
    "\n",
    "            if model_type in [\"xlm\", \"roberta\", \"distilbert\", \"camembert\", \"bart\", \"longformer\"]:\n",
    "                del inputs[\"token_type_ids\"]\n",
    "\n",
    "            feature_indices = batch[3]\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        for i, feature_index in enumerate(feature_indices):\n",
    "            eval_feature = features[feature_index.item()]\n",
    "            unique_id = int(eval_feature.unique_id)\n",
    "\n",
    "            start_logits = outputs.start_logits\n",
    "            end_logits = outputs.end_logits\n",
    "            attentions = get_layers(outputs.attentions)\n",
    "\n",
    "            result = SquadResult(unique_id, start_logits, end_logits)\n",
    "            all_results.append(result)\n",
    "\n",
    "#             append_list_as_row('QA_bert_attentions.csv', attentions)\n",
    "            all_attentions.append(attentions)\n",
    "\n",
    "    \n",
    "            attn_count += 1\n",
    "            if attn_count % 500 == 0:\n",
    "#                 representation_array = []\n",
    "#                 for i, attentions in enumerate(all_attentions):\n",
    "                logger.info(\"Scaling attention values to 0-255 ...\")\n",
    "                representations = scale_examples(all_attentions)\n",
    "                logger.info(\"Processing to 2048 value representations through barlow_twins ...\")\n",
    "                representations = get_representations(representations)\n",
    "                logger.info(\"Appending results to array/dataframe ...\")\n",
    "                representations = flatten_layer_heads(representations)\n",
    "#                 representation_array.append(flat_representations)\n",
    "                df = pd.DataFrame(representations)\n",
    "                df = pd.DataFrame([pd.Series(x) for x in df[0]])\n",
    "                representation_df = representation_df.append(df, ignore_index=True)\n",
    "#                 logger.info(\"  Outputting Attention File %s eval_attentions %i\", output_dir, attn_count)\n",
    "#                 torch.save(all_attentions, \"QA_attentions_pickled/eval_attentions_\" +str(attn_count)+\".bin\")\n",
    "#                 representation_df.to_csv(os.path.join(data_dir, f\"representation_df_{attn_count}.csv\"))\n",
    "                print(f\"--- eval to representation batch {attn_count} ---\")          \n",
    "                all_attentions = []\n",
    "                representations = []\n",
    "                df = pd.DataFrame()\n",
    "            \n",
    "            if attn_count % 5000 == 0:\n",
    "                logger.info(f\"  Outputting Attention File representation_df_{attn_count} to {representation_dir}\")\n",
    "                representation_df.to_csv(os.path.join(representation_dir, f\"representation_df_{attn_count}.csv\"))\n",
    "                representation_df = pd.DataFrame()\n",
    "\n",
    "    evalTime = timeit.default_timer() - start_time\n",
    "    logger.info(\"  Evaluation done in total %f secs (%f sec per example)\", evalTime, evalTime / len(dataset))\n",
    "#     global_attention = all_attentions\n",
    "#     logger.info(\"  Outputting Attention File %s eval_attentions.bin\", output_dir)\n",
    "#     torch.save(all_attentions, os.path.join(output_dir, \"eval_attentions.bin\"))\n",
    "    \n",
    "\n",
    "    \n",
    "#     with open(os.path.join(output_dir, \"eval_attentions.pkl\"), 'wb') as attention_file:\n",
    "#       pickle.dump(all_attentions, attention_file)\n",
    "\n",
    "    # Compute predictions\n",
    "    output_prediction_file = os.path.join(output_dir, \"predictions_{}.json\".format(prefix))\n",
    "    output_nbest_file = os.path.join(output_dir, \"nbest_predictions_{}.json\".format(prefix))\n",
    "\n",
    "    if version_2_with_negative:\n",
    "        output_null_log_odds_file = os.path.join(output_dir, \"null_odds_{}.json\".format(prefix))\n",
    "    else:\n",
    "        output_null_log_odds_file = None\n",
    "\n",
    "    # XLNet and XLM use a more complex post-processing procedure\n",
    "    if args.model_type in [\"xlnet\", \"xlm\"]:\n",
    "        start_n_top = model.config.start_n_top if hasattr(model, \"config\") else model.module.config.start_n_top\n",
    "        end_n_top = model.config.end_n_top if hasattr(model, \"config\") else model.module.config.end_n_top\n",
    "\n",
    "        predictions = compute_predictions_log_probs(\n",
    "            examples,\n",
    "            features,\n",
    "            all_results,\n",
    "            args.n_best_size,\n",
    "            args.max_answer_length,\n",
    "            output_prediction_file,\n",
    "            output_nbest_file,\n",
    "            output_null_log_odds_file,\n",
    "            start_n_top,\n",
    "            end_n_top,\n",
    "            args.version_2_with_negative,\n",
    "            tokenizer,\n",
    "            args.verbose_logging,\n",
    "        )\n",
    "    else:\n",
    "        predictions = compute_predictions_logits(\n",
    "            examples,\n",
    "            features,\n",
    "            all_results,\n",
    "            n_best_size,\n",
    "            max_answer_length,\n",
    "            do_lower_case,\n",
    "            output_prediction_file,\n",
    "            output_nbest_file,\n",
    "            output_null_log_odds_file,\n",
    "            verbose_logging,\n",
    "            version_2_with_negative,\n",
    "            null_score_diff_threshold,\n",
    "            tokenizer,\n",
    "        )\n",
    "\n",
    "    # Compute the F1 and exact scores.\n",
    "    results = squad_evaluate(examples, predictions)\n",
    "    return results\n",
    "\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(attention, num_layers=12, num_heads=12):\n",
    "  layers = np.ndarray((num_heads,num_layers), np.ndarray)\n",
    "  for i, layer in enumerate(attention):\n",
    "    layer = layer.detach().cpu().numpy()[0]\n",
    "    for j, head in enumerate(layer):\n",
    "      layers[i,j] = head\n",
    "  return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from csv import writer\n",
    "def append_list_as_row(file_name, list_of_elem):\n",
    "    # Open file in append mode\n",
    "    with open(file_name, 'a+', newline='') as write_obj:\n",
    "        # Create a writer object from csv module\n",
    "        csv_writer = writer(write_obj)\n",
    "        # Add contents of list as last row in the csv file\n",
    "        csv_writer.writerow(list_of_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_and_cache_examples(args, tokenizer, evaluate=False, output_examples=False):\n",
    "    # Load data features from cache or dataset file\n",
    "#     input_dir = data_dir else \".\"\n",
    "\n",
    "    cached_features_file = os.path.join(\n",
    "        input_dir,\n",
    "        \"cached_{}_{}_{}\".format(\n",
    "            \"train\",\n",
    "            list(filter(None, model_name_or_path.split(\"/\"))).pop(),\n",
    "            str(max_seq_length),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    logger.info(\"cached features file: %s\", cached_features_file)\n",
    "#     Init features and dataset from cache if it exists\n",
    "    if os.path.exists(cached_features_file):\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features_and_dataset = torch.load(cached_features_file)\n",
    "        features, dataset, examples = (\n",
    "            features_and_dataset[\"features\"],\n",
    "            features_and_dataset[\"dataset\"],\n",
    "            features_and_dataset[\"examples\"],\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", input_dir)\n",
    "\n",
    "        examples = processor.get_train_examples(input_dir, filename=train_file)\n",
    "\n",
    "        logger.info(\"Got features from dataset file at %s\", input_dir)\n",
    "\n",
    "        features, dataset = squad_convert_examples_to_features(\n",
    "            examples=examples,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_length=max_seq_length,\n",
    "            doc_stride=doc_stride,\n",
    "            max_query_length=max_query_length,\n",
    "            is_training=False,\n",
    "            return_dataset=\"pt\",\n",
    "            threads=threads,\n",
    "        )\n",
    "\n",
    "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "        torch.save({\"features\": features, \"dataset\": dataset, \"examples\": examples}, cached_features_file)\n",
    "\n",
    "    if output_examples:\n",
    "        return dataset, examples, features\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/13/2021 18:03:36 - WARNING - __main__ -   device: cuda:1, n_gpu: 1\n",
      "[INFO|configuration_utils.py:528] 2021-07-13 18:03:36,612 >> loading configuration file models/bert/config.json\n",
      "[INFO|configuration_utils.py:566] 2021-07-13 18:03:36,613 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1651] 2021-07-13 18:03:36,614 >> Didn't find file models/bert/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1651] 2021-07-13 18:03:36,615 >> Didn't find file models/bert/tokenizer.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1715] 2021-07-13 18:03:36,615 >> loading file models/bert/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1715] 2021-07-13 18:03:36,616 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1715] 2021-07-13 18:03:36,616 >> loading file models/bert/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1715] 2021-07-13 18:03:36,617 >> loading file models/bert/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1715] 2021-07-13 18:03:36,617 >> loading file None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger.warning(\n",
    "    \"device: %s, n_gpu: %s\",\n",
    "    device,\n",
    "    n_gpu\n",
    ")\n",
    "# Set the verbosity to info of the Transformers logger (on main process only):\n",
    "# if is_main_process(args.local_rank):\n",
    "transformers.utils.logging.set_verbosity_info()\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "# Set seed\n",
    "set_seed(42)\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "config = BertConfig.from_pretrained(model_name_or_path, output_attentions=True) # no config_path?\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    do_lower_case=True,\n",
    "    cache_dir=input_dir,\n",
    "    use_fast=False,  # SquadDataset is not compatible with Fast tokenizers which have a smarter overflow handeling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:528] 2021-07-13 18:03:36,722 >> loading configuration file models/bert/config.json\n",
      "[INFO|configuration_utils.py:566] 2021-07-13 18:03:36,723 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1159] 2021-07-13 18:03:36,724 >> loading weights file models/bert/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1345] 2021-07-13 18:03:37,532 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1354] 2021-07-13 18:03:37,533 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at models/bert/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "07/13/2021 18:03:37 - INFO - __main__ -   cached features file: ./data/squad/cached_train_bert_384\n",
      "07/13/2021 18:03:37 - INFO - __main__ -   Loading features from cached file ./data/squad/cached_train_bert_384\n",
      "07/13/2021 18:05:19 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "07/13/2021 18:05:19 - INFO - __main__ -     Num examples = 131944\n",
      "07/13/2021 18:05:19 - INFO - __main__ -     Batch size = 1\n",
      "Evaluating:   0%|          | 499/131944 [00:27<2:00:06, 18.24it/s]07/13/2021 18:05:46 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   0%|          | 499/131944 [00:39<2:00:06, 18.24it/s]07/13/2021 18:06:52 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "07/13/2021 18:20:56 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 502/131944 [15:54<3971:44:21, 108.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 997/131944 [16:05<50:44, 43.01it/s]      07/13/2021 18:21:25 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   1%|          | 997/131944 [16:21<50:44, 43.01it/s]07/13/2021 18:22:17 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 18:36:31 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   1%|          | 1000/131944 [31:29<2291:36:20, 63.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 1498/131944 [31:43<50:41, 42.89it/s]     07/13/2021 18:37:02 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   1%|          | 1498/131944 [32:01<50:41, 42.89it/s]07/13/2021 18:37:55 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 18:52:04 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 1503/131944 [47:01<1854:27:21, 51.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 1500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   2%|▏         | 1998/131944 [47:15<50:41, 42.72it/s]     07/13/2021 18:52:35 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   2%|▏         | 1998/131944 [47:31<50:41, 42.72it/s]07/13/2021 18:53:28 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 19:07:37 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   2%|▏         | 2004/131944 [1:02:37<1717:02:00, 47.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 2000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   2%|▏         | 2499/131944 [1:02:49<50:23, 42.81it/s]     07/13/2021 19:08:08 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   2%|▏         | 2499/131944 [1:03:01<50:23, 42.81it/s]07/13/2021 19:09:01 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 19:23:14 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   2%|▏         | 2503/131944 [1:18:12<1958:27:37, 54.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 2500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   2%|▏         | 2998/131944 [1:18:23<50:22, 42.66it/s]     07/13/2021 19:23:43 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   2%|▏         | 2998/131944 [1:18:41<50:22, 42.66it/s]07/13/2021 19:24:35 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 19:38:47 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   2%|▏         | 3003/131944 [1:33:47<1844:22:11, 51.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 3000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   3%|▎         | 3498/131944 [1:33:59<49:50, 42.95it/s]     07/13/2021 19:39:19 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   3%|▎         | 3498/131944 [1:34:11<49:50, 42.95it/s]07/13/2021 19:40:11 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 19:54:20 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   3%|▎         | 3500/131944 [1:49:18<2399:12:49, 67.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 3500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   3%|▎         | 3999/131944 [1:49:29<50:18, 42.39it/s]     07/13/2021 19:54:49 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   3%|▎         | 3999/131944 [1:49:41<50:18, 42.39it/s]07/13/2021 19:55:41 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 20:09:54 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   3%|▎         | 4003/131944 [2:04:52<1935:13:12, 54.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 4000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   3%|▎         | 4498/131944 [2:05:04<49:37, 42.81it/s]     07/13/2021 20:10:23 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   3%|▎         | 4498/131944 [2:05:21<49:37, 42.81it/s]07/13/2021 20:11:16 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 20:25:25 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   3%|▎         | 4504/131944 [2:20:26<1684:18:25, 47.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 4500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   4%|▍         | 4999/131944 [2:20:37<49:02, 43.14it/s]     07/13/2021 20:25:57 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   4%|▍         | 4999/131944 [2:20:53<49:02, 43.14it/s]07/13/2021 20:26:49 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 20:40:53 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/13/2021 20:41:13 - INFO - __main__ -     Outputting Attention File representation_df_5000 to /rapids/notebooks/host/QA_attentions_pickled/representations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 5000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   4%|▍         | 5499/131944 [2:59:18<49:20, 42.72it/s]      07/13/2021 21:04:38 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   4%|▍         | 5499/131944 [2:59:34<49:20, 42.72it/s]07/13/2021 21:05:32 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 21:19:56 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   4%|▍         | 5503/131944 [3:14:57<1944:28:43, 55.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 5500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   5%|▍         | 5998/131944 [3:15:08<49:01, 42.81it/s]     07/13/2021 21:20:28 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   5%|▍         | 5998/131944 [3:15:25<49:01, 42.81it/s]07/13/2021 21:21:21 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 21:35:48 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   5%|▍         | 6002/131944 [3:30:49<1991:34:05, 56.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 6000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   5%|▍         | 6497/131944 [3:31:00<48:50, 42.81it/s]     07/13/2021 21:36:20 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   5%|▍         | 6497/131944 [3:31:15<48:50, 42.81it/s]07/13/2021 21:37:12 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 21:51:40 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   5%|▍         | 6503/131944 [3:46:37<1723:45:47, 49.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 6500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   5%|▌         | 6998/131944 [3:46:49<48:43, 42.73it/s]     07/13/2021 21:52:09 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   5%|▌         | 6998/131944 [3:47:05<48:43, 42.73it/s]07/13/2021 21:53:02 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 22:07:28 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   5%|▌         | 7000/131944 [4:02:28<2386:08:30, 68.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 7000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   6%|▌         | 7498/131944 [4:02:40<48:41, 42.60it/s]     07/13/2021 22:08:00 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   6%|▌         | 7498/131944 [4:02:56<48:41, 42.60it/s]07/13/2021 22:08:53 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 22:23:16 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   6%|▌         | 7504/131944 [4:18:17<1671:38:14, 48.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 7500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   6%|▌         | 7999/131944 [4:18:29<48:16, 42.80it/s]     07/13/2021 22:23:48 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   6%|▌         | 7999/131944 [4:18:46<48:16, 42.80it/s]07/13/2021 22:24:41 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 22:39:06 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   6%|▌         | 8004/131944 [4:34:07<1758:18:40, 51.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 8000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   6%|▋         | 8499/131944 [4:34:19<48:25, 42.48it/s]     07/13/2021 22:39:38 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   6%|▋         | 8499/131944 [4:34:36<48:25, 42.48it/s]07/13/2021 22:40:31 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 22:54:30 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   6%|▋         | 8500/131944 [4:49:28<2462:07:43, 71.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 8500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   7%|▋         | 8998/131944 [4:49:40<47:31, 43.11it/s]     07/13/2021 22:54:59 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   7%|▋         | 8998/131944 [4:49:56<47:31, 43.11it/s]07/13/2021 22:55:51 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 23:09:43 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   7%|▋         | 9003/131944 [5:04:44<1720:44:05, 50.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 9000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   7%|▋         | 9498/131944 [5:04:55<47:20, 43.11it/s]     07/13/2021 23:10:15 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   7%|▋         | 9498/131944 [5:05:07<47:20, 43.11it/s]07/13/2021 23:11:07 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 23:24:59 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   7%|▋         | 9502/131944 [5:19:57<1856:34:15, 54.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 9500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   8%|▊         | 9997/131944 [5:20:09<48:20, 42.04it/s]     07/13/2021 23:25:28 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   8%|▊         | 9997/131944 [5:20:27<48:20, 42.04it/s]07/13/2021 23:26:20 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/13/2021 23:40:25 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/13/2021 23:40:45 - INFO - __main__ -     Outputting Attention File representation_df_10000 to /rapids/notebooks/host/QA_attentions_pickled/representations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 10000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   8%|▊         | 10499/131944 [5:58:37<47:35, 42.53it/s]      07/14/2021 00:03:56 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   8%|▊         | 10499/131944 [5:58:50<47:35, 42.53it/s]07/14/2021 00:04:49 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/14/2021 00:19:14 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   8%|▊         | 10504/131944 [6:14:15<1722:11:15, 51.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 10500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   8%|▊         | 10999/131944 [6:14:26<47:06, 42.79it/s]     07/14/2021 00:19:46 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   8%|▊         | 10999/131944 [6:14:40<47:06, 42.79it/s]07/14/2021 00:20:38 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/14/2021 00:34:42 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   8%|▊         | 11002/131944 [6:29:42<1982:17:19, 59.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 11000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   9%|▊         | 11497/131944 [6:29:54<46:35, 43.08it/s]     07/14/2021 00:35:13 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   9%|▊         | 11497/131944 [6:30:10<46:35, 43.08it/s]07/14/2021 00:36:05 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/14/2021 00:50:10 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   9%|▊         | 11504/131944 [6:45:10<1505:15:05, 44.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 11500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   9%|▉         | 11999/131944 [6:45:22<46:18, 43.18it/s]     07/14/2021 00:50:41 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   9%|▉         | 11999/131944 [6:45:40<46:18, 43.18it/s]07/14/2021 00:51:33 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/14/2021 01:05:24 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   9%|▉         | 12003/131944 [7:00:22<1769:48:41, 53.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 12000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   9%|▉         | 12498/131944 [7:00:33<46:00, 43.27it/s]     07/14/2021 01:05:53 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:   9%|▉         | 12498/131944 [7:00:50<46:00, 43.27it/s]07/14/2021 01:06:45 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "07/14/2021 01:20:36 - INFO - __main__ -   Appending results to array/dataframe ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening layers/heads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   9%|▉         | 12502/131944 [7:15:36<1813:54:48, 54.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- eval to representation batch 12500 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  10%|▉         | 12997/131944 [7:15:48<45:47, 43.29it/s]     07/14/2021 01:21:08 - INFO - __main__ -   Scaling attention values to 0-255 ...\n",
      "Evaluating:  10%|▉         | 12997/131944 [7:16:00<45:47, 43.29it/s]07/14/2021 01:21:59 - INFO - __main__ -   Processing to 2048 value representations through barlow_twins ...\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model = AutoModelForQuestionAnswering.from_pretrained(model_name_or_path, output_attentions=True)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name_or_path, output_attentions=True)\n",
    "device = \"cuda:1\"\n",
    "model = model.to(device)\n",
    "# Evaluate\n",
    "processor = SquadV2Processor() if version_2_with_negative else SquadV1Processor()\n",
    "result = evaluate({'data_dir': \"\"}, model, tokenizer)\n",
    "\n",
    "result = dict((k + (\"_{}\".format(global_step) if global_step else \"\"), v) for k, v in result.items())\n",
    "results.update(result)\n",
    "\n",
    "logger.info(\"Results: {}\".format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-78f7129200a9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-78f7129200a9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    qrr = [0.03609005,0.02730089,0.01784932,0.00970263,0.03209871,0.02975531,0.01899219,0.0159386,0.09006939,0.00353505,0.00430149,0.00373916,0.004033,0.0054037,0.00314571,0.00544514,0.00577388,0.00909712,0.00366947,0.00779078,0.0060854,0.00374152,0.00431431,0.00433876,0.00607211,0.00415887,0.00477201,0.00399395,0.00448466,0.00406087,0.00554479,0.00403477,0.00403658,0.00570019,0.00253348,0.00786278,0.00268425,0.00286821,0.00445756,0.00259511,0.01361431,0.00179666,0.00279525,0.00253426,0.00443048,0.00275498,0.00693157,0.00444886,0.00678853,0.00411692,0.0071019,0.00660669,0.00816385,0.00570161,0.00614765,0.00302077,0.00278247,0.00188732,0.00286246,0.00246164,0.00384467,0.00554711,0.00819303,0.00627691,0.00650617,0.00496393,0.00559988,0.00612233,0.01119899,0.00860447,0.00352704,0.0071039,0.00396436,0.00965003,0.00511713,0.00618074,0.00690801,0.00618426,0.0035491,0.00724508,0.00985016,0.00404688,0.00427996,0.00285223,0.00245299,0.00591965,0.00313316,0.00378624,0.00741692,0.00399197,0.00309289,0.00225511,0.00550424,0.00611447,0.00585844,0.00925419,0.00312216,0.00596423,0.00268668,0.0018134,0.00285068,0.00261073,0.00597714,0.00725985,0.00449176,0.01075981,0.00320032,0.00597627,0.00291104,0.00275812,0.00203771,0.00306792,0.00339498,0.00513527,0.00229073,0.00349129,0.00306995,0.00403183,0.00349238,0.00516681,0.00469688,0.00314611,0.00399399,0.00605243,0.00566731,0.00388196,0.00273817,0.00305755,0.00224174,0.00391221,0.00251756,0.00190409,0.00828339,0.00398148,0.00303265,0.00302295,0.00196971,0.00284096,0.00145757,0.00371954,0.00356667,0.00184108,0.0033674,0.00493111,0.00370861,0.00118721,0.00130349,0.00143106,0.00201871,0.00370352,0.00239526,0.00200266,0.00348562,0.00141907,0.00355505,0.00185585,0.00149471,0.002439,0.00457984,0.00260334,0.00734435,0.00277519,0.0014447,,0.00187251,0.00321797,0.00269519,0.00156433,0.0038524,0.00148884,0.00231959,0.00253542,0.00174283,0.00346243,0.01599906,\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "qrr = [0.03609005,0.02730089,0.01784932,0.00970263,0.03209871,0.02975531,0.01899219,0.0159386,0.09006939,0.00353505,0.00430149,0.00373916,0.004033,0.0054037,0.00314571,0.00544514,0.00577388,0.00909712,0.00366947,0.00779078,0.0060854,0.00374152,0.00431431,0.00433876,0.00607211,0.00415887,0.00477201,0.00399395,0.00448466,0.00406087,0.00554479,0.00403477,0.00403658,0.00570019,0.00253348,0.00786278,0.00268425,0.00286821,0.00445756,0.00259511,0.01361431,0.00179666,0.00279525,0.00253426,0.00443048,0.00275498,0.00693157,0.00444886,0.00678853,0.00411692,0.0071019,0.00660669,0.00816385,0.00570161,0.00614765,0.00302077,0.00278247,0.00188732,0.00286246,0.00246164,0.00384467,0.00554711,0.00819303,0.00627691,0.00650617,0.00496393,0.00559988,0.00612233,0.01119899,0.00860447,0.00352704,0.0071039,0.00396436,0.00965003,0.00511713,0.00618074,0.00690801,0.00618426,0.0035491,0.00724508,0.00985016,0.00404688,0.00427996,0.00285223,0.00245299,0.00591965,0.00313316,0.00378624,0.00741692,0.00399197,0.00309289,0.00225511,0.00550424,0.00611447,0.00585844,0.00925419,0.00312216,0.00596423,0.00268668,0.0018134,0.00285068,0.00261073,0.00597714,0.00725985,0.00449176,0.01075981,0.00320032,0.00597627,0.00291104,0.00275812,0.00203771,0.00306792,0.00339498,0.00513527,0.00229073,0.00349129,0.00306995,0.00403183,0.00349238,0.00516681,0.00469688,0.00314611,0.00399399,0.00605243,0.00566731,0.00388196,0.00273817,0.00305755,0.00224174,0.00391221,0.00251756,0.00190409,0.00828339,0.00398148,0.00303265,0.00302295,0.00196971,0.00284096,0.00145757,0.00371954,0.00356667,0.00184108,0.0033674,0.00493111,0.00370861,0.00118721,0.00130349,0.00143106,0.00201871,0.00370352,0.00239526,0.00200266,0.00348562,0.00141907,0.00355505,0.00185585,0.00149471,0.002439,0.00457984,0.00260334,0.00734435,0.00277519,0.0014447,,0.00187251,0.00321797,0.00269519,0.00156433,0.0038524,0.00148884,0.00231959,0.00253542,0.00174283,0.00346243,0.01599906,\n",
    "0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.,\n",
    " 0.,0.,0.,0.,0.,0.        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
