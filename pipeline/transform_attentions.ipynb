{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Attentions\n",
    "\n",
    "With confidence in our transformation process that we investigated in exploration/transform_prototyping, we process our first 2000 squad examples worth of attentions from exploration/extract_attentions.ipynb as 20 * 10GB binary pkl files.  This resulted in a 6.6GB CSV.\n",
    "\n",
    "Transform Steps (for each file):\n",
    "\n",
    "• Load attention binary  \n",
    "• Scale attention values to 0-255  \n",
    "• Reshape to (1, 3, 384, 384) tensor  \n",
    "• Extract features using modified Barlow Twins  \n",
    "• Flatten 12x12 representations  \n",
    "• Convert tensors to dataframe columns  \n",
    "• Append to dataframe  \n",
    "\n",
    "Results are then output to representations_df.csv which was used in initial clustering exploration and scaling analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 255)) # scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/tf/notebooks/QA_attentions_pickled'\n",
    "output_dir='/tf/notebooks/QA_attentions_pickled/representations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
    "model.fc = Identity() # pass through values from second to last layer, bypassing linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.device('cuda:0')\n",
    "model.to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer_heads(attention, num_layers=12, num_heads=12):\n",
    "  for i in range(0,11):\n",
    "    p = attention[i]\n",
    "    fig, axis = plt.subplots(1,12, figsize=(20,5), facecolor='w', edgecolor='k')\n",
    "    plt.title(f'layer {i}')\n",
    "    head = 0\n",
    "    for axs, ph in zip(axis.flatten(), p):\n",
    "      heatmap = axs.imshow(ph, cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_examples(examples):\n",
    "    scaled_examples = np.empty(shape=(100), dtype=np.ndarray)\n",
    "    for i, example in enumerate(examples):\n",
    "        new_example = np.empty(shape=(12,12), dtype=np.ndarray)\n",
    "        for l, layer in enumerate(example): #12 layers\n",
    "            new_layer = np.array([])\n",
    "            for h, head in enumerate(layer): #12 heads\n",
    "                flat_head_transformed = scaler.fit_transform(head)\n",
    "                new_example[l,h] = flat_head_transformed.reshape(384,384)\n",
    "        scaled_examples[i] = new_example\n",
    "    return scaled_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create (1, 3, 384, 384) shape expected by barlow twins model\n",
    "def reshape_example(image):\n",
    "    example_channel = np.expand_dims(image, axis=0)\n",
    "    batch = np.append(example_channel, example_channel, axis=0)\n",
    "    batch = np.append(batch, example_channel, axis=0)\n",
    "    example_3channel = np.expand_dims(batch, axis=0)\n",
    "    return example_3channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representations(attentions):\n",
    "    barlow_representations = np.zeros((100), np.object)\n",
    "    for i, example in enumerate(attentions):\n",
    "        reshaped_example = np.zeros((12,12), np.object)\n",
    "        for l, layer in enumerate(example):\n",
    "            for h, head in enumerate(layer):\n",
    "                reshaped_head = torch.from_numpy(reshape_example(head)).to(cuda)\n",
    "                representation_head = model(reshaped_head.float())\n",
    "                reshaped_example[l][h] = representation_head.detach().cpu().numpy()\n",
    "        barlow_representations[i] = reshaped_example\n",
    "\n",
    "    return barlow_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer_heads(representations_tensor):\n",
    "    print(\"flattening layers/heads ...\")\n",
    "    flat_array = np.zeros((14400), np.ndarray)\n",
    "    i = 0\n",
    "    for example in representations_tensor:\n",
    "        for layer in example:\n",
    "            for h, head in enumerate(layer):\n",
    "                flat_array[i] = head[0]\n",
    "                i += 1\n",
    "    return flat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading attentions batch 100\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 100 in  217.97882652282715 seconds ---\n",
      "Loading attentions batch 200\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 200 in  226.08006763458252 seconds ---\n",
      "Loading attentions batch 300\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 300 in  224.35632610321045 seconds ---\n",
      "Loading attentions batch 400\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 400 in  227.2799997329712 seconds ---\n",
      "Loading attentions batch 500\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 500 in  229.1076455116272 seconds ---\n",
      "Loading attentions batch 600\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 600 in  222.65755248069763 seconds ---\n",
      "Loading attentions batch 700\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 700 in  229.7725477218628 seconds ---\n",
      "Loading attentions batch 800\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 800 in  228.96797132492065 seconds ---\n",
      "Loading attentions batch 900\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 900 in  223.4004237651825 seconds ---\n",
      "Loading attentions batch 1000\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 1000 in  227.5881745815277 seconds ---\n",
      "Loading attentions batch 1100\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 1100 in  232.6067202091217 seconds ---\n",
      "Loading attentions batch 1200\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 1200 in  232.0296766757965 seconds ---\n",
      "Loading attentions batch 1300\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 1300 in  220.02137064933777 seconds ---\n",
      "Loading attentions batch 1400\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 1400 in  222.25109148025513 seconds ---\n",
      "Loading attentions batch 1500\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 1500 in  225.96831512451172 seconds ---\n",
      "Loading attentions batch 1600\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 1600 in  226.30343580245972 seconds ---\n",
      "Loading attentions batch 1700\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 1700 in  229.7463562488556 seconds ---\n",
      "Loading attentions batch 1800\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 1800 in  232.077006816864 seconds ---\n",
      "Loading attentions batch 1900\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 1900 in  223.7429916858673 seconds ---\n",
      "Loading attentions batch 2000\n",
      "Scaling attention values to 0-255 ...\n",
      "Processing to 2048 value representations through barlow_twins ...\n",
      "Appending results to array/dataframe ...\n",
      "flattening layers/heads ...\n",
      "--- eval to representation batch 2000 in  222.06531167030334 seconds ---\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "batch_num = 0\n",
    "representation_df = pd.DataFrame()\n",
    "representation_array = []\n",
    "for i in range(1,21):\n",
    "    start_time = time.time()\n",
    "    batch_num = i * batch_size\n",
    "    print(f\"Loading attentions batch {batch_num}\")\n",
    "    attentions = torch.load(os.path.join(data_dir, f\"eval_attentions_{batch_num}.bin\"))\n",
    "    print(\"Scaling attention values to 0-255 ...\")\n",
    "    scaled_attentions =  scale_examples(attentions)\n",
    "    print(\"Processing to 2048 value representations through barlow_twins ...\")\n",
    "    barlow_representations = get_representations(scaled_attentions)\n",
    "    print(\"Appending results to array/dataframe ...\")\n",
    "    flat_representations = flatten_layer_heads(barlow_representations)\n",
    "    representation_array.append(flat_representations)\n",
    "    df = pd.DataFrame(flat_representations)\n",
    "    df = pd.DataFrame([pd.Series(x) for x in df[0]])\n",
    "    representation_df = representation_df.append(df, ignore_index=True)\n",
    "    print(f\"--- eval to representation batch {batch_num} in  {(time.time() - start_time)} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(representation_array,os.path.join(data_dir, f\"representation_array.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(representation_df,os.path.join(data_dir, f\"representation_df.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_df.to_csv(os.path.join(data_dir, f\"representation_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.021541</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0.024328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.122129</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.016769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057488</td>\n",
       "      <td>0.025694</td>\n",
       "      <td>0.012562</td>\n",
       "      <td>0.095822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.02578</td>\n",
       "      <td>0.00421</td>\n",
       "      <td>0.00793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4     5         6         7     \\\n",
       "0  0.001772  0.021541  0.001335  0.022821  0.024328   0.0  0.032967  0.122129   \n",
       "\n",
       "       8         9     ...      2038      2039      2040      2041  2042  \\\n",
       "0  0.014402  0.016769  ...  0.057488  0.025694  0.012562  0.095822   0.0   \n",
       "\n",
       "      2043      2044     2045     2046     2047  \n",
       "0  0.02446  0.003141  0.02578  0.00421  0.00793  \n",
       "\n",
       "[1 rows x 2048 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representation_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(flat_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([pd.Series(x) for x in df[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_df = representation_df.append(df, ignore_index=True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.021541</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0.024328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.122129</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.016769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057488</td>\n",
       "      <td>0.025694</td>\n",
       "      <td>0.012562</td>\n",
       "      <td>0.095822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.02578</td>\n",
       "      <td>0.00421</td>\n",
       "      <td>0.00793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4     5         6         7     \\\n",
       "0  0.001772  0.021541  0.001335  0.022821  0.024328   0.0  0.032967  0.122129   \n",
       "\n",
       "       8         9     ...      2038      2039      2040      2041  2042  \\\n",
       "0  0.014402  0.016769  ...  0.057488  0.025694  0.012562  0.095822   0.0   \n",
       "\n",
       "      2043      2044     2045     2046     2047  \n",
       "0  0.02446  0.003141  0.02578  0.00421  0.00793  \n",
       "\n",
       "[1 rows x 2048 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representation_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 288000 entries, 0 to 287999\n",
      "Columns: 2048 entries, 0 to 2047\n",
      "dtypes: float32(2048)\n",
      "memory usage: 2.2 GB\n"
     ]
    }
   ],
   "source": [
    "representation_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of             0         1         2         3         4         5         6     \\\n",
       "0       0.001772  0.021541  0.001335  0.022821  0.024328  0.000000  0.032967   \n",
       "1       0.000670  0.007020  0.084146  0.023934  0.032102  0.000000  0.030618   \n",
       "2       0.009630  0.009985  0.004485  0.030183  0.045801  0.002238  0.050636   \n",
       "3       0.002628  0.004462  0.012899  0.028588  0.077253  0.000000  0.007670   \n",
       "4       0.001193  0.077093  0.037766  0.050492  0.005282  0.003195  0.038456   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "287995  0.000908  0.006504  0.013558  0.011609  0.000802  0.007187  0.044382   \n",
       "287996  0.000000  0.008056  0.052457  0.006509  0.014854  0.000809  0.022595   \n",
       "287997  0.000274  0.014337  0.031389  0.016458  0.006799  0.000000  0.005014   \n",
       "287998  0.000066  0.013728  0.034654  0.015540  0.001389  0.000000  0.009813   \n",
       "287999  0.000000  0.000373  0.020018  0.014481  0.000000  0.018589  0.005801   \n",
       "\n",
       "            7         8         9     ...      2038      2039      2040  \\\n",
       "0       0.122129  0.014402  0.016769  ...  0.057488  0.025694  0.012562   \n",
       "1       0.098956  0.000224  0.006734  ...  0.017547  0.005710  0.014527   \n",
       "2       0.044660  0.000000  0.003471  ...  0.032532  0.010281  0.010031   \n",
       "3       0.048101  0.022565  0.010286  ...  0.034638  0.000000  0.002906   \n",
       "4       0.040593  0.000439  0.018679  ...  0.027949  0.041166  0.021754   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "287995  0.082220  0.014034  0.008913  ...  0.021726  0.001194  0.000000   \n",
       "287996  0.053064  0.002815  0.007026  ...  0.006301  0.006884  0.000000   \n",
       "287997  0.089540  0.000000  0.012351  ...  0.005249  0.002739  0.013482   \n",
       "287998  0.084002  0.022343  0.001832  ...  0.008953  0.001508  0.004517   \n",
       "287999  0.084570  0.006261  0.010913  ...  0.008950  0.001685  0.003659   \n",
       "\n",
       "            2041      2042      2043      2044      2045      2046      2047  \n",
       "0       0.095822  0.000000  0.024460  0.003141  0.025780  0.004210  0.007930  \n",
       "1       0.072816  0.000360  0.022191  0.000000  0.001935  0.009656  0.031657  \n",
       "2       0.069365  0.005495  0.020031  0.008574  0.015054  0.004189  0.021220  \n",
       "3       0.066101  0.005895  0.032426  0.001703  0.005066  0.005220  0.023971  \n",
       "4       0.078195  0.020036  0.008875  0.010718  0.051700  0.000488  0.006829  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "287995  0.105841  0.000417  0.024954  0.000000  0.000000  0.017875  0.024631  \n",
       "287996  0.076538  0.000000  0.016855  0.000000  0.000271  0.002566  0.070915  \n",
       "287997  0.119142  0.000000  0.011397  0.000000  0.000000  0.006279  0.014027  \n",
       "287998  0.115007  0.000000  0.003047  0.000054  0.000000  0.001574  0.011174  \n",
       "287999  0.086822  0.000000  0.024041  0.000881  0.000000  0.004966  0.013639  \n",
       "\n",
       "[288000 rows x 2048 columns]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representation_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
