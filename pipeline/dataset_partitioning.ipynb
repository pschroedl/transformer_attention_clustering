{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50072f78-0b7d-4255-8648-54a6b8b07b5c",
   "metadata": {},
   "source": [
    "# Partitioning the 130k Squad2 Dataset\n",
    "\n",
    "Due to memory constraints, we're unable to run clustering on the entire 400gb transformed dataset.\n",
    "\n",
    "In order to get a representational subset of the squad2 examples, a number of examples (43,200 rows) were extracted from each of the files output from our pipeline.  As each context typically can have a number of questions associated with it, sampling in this  manner is preferable to a fully sequential sub-sampling as we can  get a better cross-section sampling of the squad2 examples.\n",
    "\n",
    "When using Dask, it is recommended that the dataset be split into 1-2gb sections before loading, so this also took care of that step for us.  There is some memory overhead using Dask/cuML vs. 1 GPU cuML, and kMeans using Dask and cuML was more memory hungry than DBSCAN, this also allows finer grained control over the size of our dataset so as to cluster as large a portion as our VRAM would allow.\n",
    "\n",
    "This notebook takes Squad2 examples 0-129999 in 26 files of 5000 examples each ( 16gb, 720,000 rows ) and subsample to 26 segment files of 300 examples apiece ( each ~1GB ).  With 144 rows / example this produces 43,200 rows per segment, 1,123,200 attention heads total = 7,800 squad2 examples sampling the entire dataset.  Filenames are output with the count value left padded to 6 digits to load sequentially when reading in as a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45db2b60-5793-4a28-86e0-efafbe19c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "logger = mp.log_to_stderr()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "data_dir='/rapids/notebooks/host/representations/final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b629f48-ae8b-4260-a6e8-497b477b877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(count, rows):\n",
    "        start_time = time.time()\n",
    "        logger.info(f'Loading segment of {count} ...')\n",
    "        df = pd.read_csv(os.path .join(data_dir,f'final_representation_df_{count}.csv'), nrows=rows)\n",
    "        logger.info(f'Writing segment {count} ...')\n",
    "        df.to_csv(os.path .join(data_dir, f'partitions/{count:06d}_partition.csv'), index=False)  \n",
    "        logger.info(f'--- Finished writing segment {count} in {(time.time() - start_time)} seconds ---\"')\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff55b88-c640-498f-82e9-dba820620ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO/ForkPoolWorker-1] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-2] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-3] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-8] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-9] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-4] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-10] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-11] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-3] Loading segment of 15000 ...\n",
      "[INFO/ForkPoolWorker-1] Loading segment of 5000 ...\n",
      "[INFO/ForkPoolWorker-9] Loading segment of 20000 ...\n",
      "[INFO/ForkPoolWorker-10] Loading segment of 35000 ...\n",
      "[INFO/ForkPoolWorker-2] Loading segment of 10000 ...\n",
      "[INFO/ForkPoolWorker-12] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-8] Loading segment of 25000 ...\n",
      "[INFO/ForkPoolWorker-11] Loading segment of 40000 ...\n",
      "[INFO/ForkPoolWorker-4] Loading segment of 30000 ...\n",
      "[INFO/ForkPoolWorker-12] Loading segment of 45000 ...\n",
      "[INFO/ForkPoolWorker-7] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-7] Loading segment of 50000 ...\n",
      "[INFO/ForkPoolWorker-6] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-6] Loading segment of 55000 ...\n",
      "[INFO/ForkPoolWorker-5] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-5] Loading segment of 60000 ...\n",
      "[INFO/ForkPoolWorker-7] Writing segment 50000 ...\n",
      "[INFO/ForkPoolWorker-10] Writing segment 35000 ...\n",
      "[INFO/ForkPoolWorker-3] Writing segment 15000 ...\n",
      "[INFO/ForkPoolWorker-2] Writing segment 10000 ...\n",
      "[INFO/ForkPoolWorker-6] Writing segment 55000 ...\n",
      "[INFO/ForkPoolWorker-11] Writing segment 40000 ...\n",
      "[INFO/ForkPoolWorker-4] Writing segment 30000 ...\n",
      "[INFO/ForkPoolWorker-8] Writing segment 25000 ...\n",
      "[INFO/ForkPoolWorker-1] Writing segment 5000 ...\n",
      "[INFO/ForkPoolWorker-5] Writing segment 60000 ...\n",
      "[INFO/ForkPoolWorker-9] Writing segment 20000 ...\n",
      "[INFO/ForkPoolWorker-12] Writing segment 45000 ...\n",
      "[INFO/ForkPoolWorker-3] --- Finished writing segment 15000 in 127.85471820831299 seconds ---\"\n",
      "[INFO/ForkPoolWorker-3] Loading segment of 65000 ...\n",
      "[INFO/ForkPoolWorker-8] --- Finished writing segment 25000 in 131.6375789642334 seconds ---\"\n",
      "[INFO/ForkPoolWorker-8] Loading segment of 70000 ...\n",
      "[INFO/ForkPoolWorker-7] --- Finished writing segment 50000 in 132.96468019485474 seconds ---\"\n",
      "[INFO/ForkPoolWorker-7] Loading segment of 75000 ...\n",
      "[INFO/ForkPoolWorker-1] --- Finished writing segment 5000 in 134.75130105018616 seconds ---\"\n",
      "[INFO/ForkPoolWorker-1] Loading segment of 80000 ...\n",
      "[INFO/ForkPoolWorker-4] --- Finished writing segment 30000 in 136.77603340148926 seconds ---\"\n",
      "[INFO/ForkPoolWorker-4] Loading segment of 85000 ...\n",
      "[INFO/ForkPoolWorker-5] --- Finished writing segment 60000 in 138.0731565952301 seconds ---\"\n",
      "[INFO/ForkPoolWorker-5] Loading segment of 90000 ...\n",
      "[INFO/ForkPoolWorker-6] --- Finished writing segment 55000 in 138.22532057762146 seconds ---\"\n",
      "[INFO/ForkPoolWorker-6] Loading segment of 95000 ...\n",
      "[INFO/ForkPoolWorker-10] --- Finished writing segment 35000 in 138.45908212661743 seconds ---\"\n",
      "[INFO/ForkPoolWorker-10] Loading segment of 100000 ...\n",
      "[INFO/ForkPoolWorker-11] --- Finished writing segment 40000 in 139.41443991661072 seconds ---\"\n",
      "[INFO/ForkPoolWorker-11] Loading segment of 105000 ...\n",
      "[INFO/ForkPoolWorker-12] --- Finished writing segment 45000 in 140.720933675766 seconds ---\"\n",
      "[INFO/ForkPoolWorker-12] Loading segment of 110000 ...\n",
      "[INFO/ForkPoolWorker-2] --- Finished writing segment 10000 in 140.93823885917664 seconds ---\"\n",
      "[INFO/ForkPoolWorker-2] Loading segment of 115000 ...\n",
      "[INFO/ForkPoolWorker-9] --- Finished writing segment 20000 in 144.480859041214 seconds ---\"\n",
      "[INFO/ForkPoolWorker-9] Loading segment of 120000 ...\n",
      "[INFO/ForkPoolWorker-3] Writing segment 65000 ...\n",
      "[INFO/ForkPoolWorker-8] Writing segment 70000 ...\n",
      "[INFO/ForkPoolWorker-4] Writing segment 85000 ...\n",
      "[INFO/ForkPoolWorker-7] Writing segment 75000 ...\n",
      "[INFO/ForkPoolWorker-6] Writing segment 95000 ...\n",
      "[INFO/ForkPoolWorker-1] Writing segment 80000 ...\n",
      "[INFO/ForkPoolWorker-10] Writing segment 100000 ...\n",
      "[INFO/ForkPoolWorker-2] Writing segment 115000 ...\n",
      "[INFO/ForkPoolWorker-5] Writing segment 90000 ...\n",
      "[INFO/ForkPoolWorker-11] Writing segment 105000 ...\n",
      "[INFO/ForkPoolWorker-12] Writing segment 110000 ...\n",
      "[INFO/ForkPoolWorker-9] Writing segment 120000 ...\n",
      "[INFO/ForkPoolWorker-3] --- Finished writing segment 65000 in 134.27066254615784 seconds ---\"\n",
      "[INFO/ForkPoolWorker-3] Loading segment of 125000 ...\n",
      "[INFO/ForkPoolWorker-4] --- Finished writing segment 85000 in 127.3188898563385 seconds ---\"\n",
      "[INFO/ForkPoolWorker-4] Loading segment of 130000 ...\n",
      "[INFO/ForkPoolWorker-2] --- Finished writing segment 115000 in 130.11388111114502 seconds ---\"\n",
      "[INFO/ForkPoolWorker-8] --- Finished writing segment 70000 in 140.1711781024933 seconds ---\"\n",
      "[INFO/ForkPoolWorker-10] --- Finished writing segment 100000 in 135.3826036453247 seconds ---\"\n",
      "[INFO/ForkPoolWorker-6] --- Finished writing segment 95000 in 136.2609260082245 seconds ---\"\n",
      "[INFO/ForkPoolWorker-7] --- Finished writing segment 75000 in 141.82154178619385 seconds ---\"\n",
      "[INFO/ForkPoolWorker-5] --- Finished writing segment 90000 in 137.38104248046875 seconds ---\"\n",
      "[INFO/ForkPoolWorker-1] --- Finished writing segment 80000 in 141.66466236114502 seconds ---\"\n",
      "[INFO/ForkPoolWorker-11] --- Finished writing segment 105000 in 138.592378616333 seconds ---\"\n",
      "[INFO/ForkPoolWorker-12] --- Finished writing segment 110000 in 138.9397749900818 seconds ---\"\n",
      "[INFO/ForkPoolWorker-9] --- Finished writing segment 120000 in 138.68768286705017 seconds ---\"\n",
      "[INFO/ForkPoolWorker-3] Writing segment 125000 ...\n",
      "[INFO/ForkPoolWorker-4] Writing segment 130000 ...\n",
      "[INFO/ForkPoolWorker-3] --- Finished writing segment 125000 in 105.74563336372375 seconds ---\"\n",
      "[INFO/ForkPoolWorker-4] --- Finished writing segment 130000 in 105.33107161521912 seconds ---\"\n",
      "[INFO/ForkPoolWorker-8] process shutting down\n"
     ]
    }
   ],
   "source": [
    "squad2_examples_per_segment = 300\n",
    "representation_rows = squad2_examples_per_segment * 12 * 12\n",
    "# 144 heads per squad2 example, 300 squad examples = 43200 - should be about 1gb\n",
    "with mp.Pool(12) as p:\n",
    "    p.map(partial(segment, rows=representation_rows), range(5000,135000,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f066263-8a8f-4fd5-a3ed-8bca6f413c17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
