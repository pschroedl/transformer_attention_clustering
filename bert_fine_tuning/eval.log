
07/23/2021 17:27:11 - INFO - __main__ -   Loading checkpoint models/bert/ for evaluation
07/23/2021 17:27:11 - INFO - __main__ -   Evaluate the following checkpoints: ['models/bert/']
[INFO|configuration_utils.py:543] 2021-07-23 17:27:11,296 >> loading configuration file models/bert/config.json
[INFO|configuration_utils.py:581] 2021-07-23 17:27:11,297 >> Model config BertConfig {
  "_name_or_path": "bert-base-uncased",
  "architectures": [
    "BertForQuestionAnswering"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_attentions": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.10.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1269] 2021-07-23 17:27:11,297 >> loading weights file models/bert/pytorch_model.bin
[INFO|modeling_utils.py:1510] 2021-07-23 17:27:12,137 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.

[INFO|modeling_utils.py:1519] 2021-07-23 17:27:12,137 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at models/bert/.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.
07/23/2021 17:27:12 - INFO - __main__ -   Loading features from cached file data/squad/cached_train_bert_384
07/23/2021 17:27:16 - INFO - __main__ -   ***** Running evaluation  *****
07/23/2021 17:27:16 - INFO - __main__ -     Num examples = 12232
07/23/2021 17:27:16 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|███████████████████████████████████████████████████████████| 1529/1529 [2:06:35<00:00,  4.97s/it]
07/23/2021 19:33:52 - INFO - __main__ -     Evaluation done in total 7595.749946 secs (0.620974 sec per example)
[INFO|squad_metrics.py:401] 2021-07-23 19:33:52,745 >> Writing predictions to: data/eval/predictions_.json
[INFO|squad_metrics.py:403] 2021-07-23 19:33:52,745 >> Writing nbest to: data/eval/nbest_predictions_.json
[INFO|squad_metrics.py:405] 2021-07-23 19:33:52,745 >> Writing null_log_odds to: data/eval/null_odds_.json
07/23/2021 19:34:32 - INFO - __main__ -   Results: {'exact': 72.95544512760044, 'f1': 76.28942043046025, 'total': 11873, 'HasAns_exact': 71.42375168690958, 'HasAns_f1': 78.10126328793105, 'HasAns_total': 5928, 'NoAns_exact': 74.48275862068965, 'NoAns_f1': 74.48275862068965, 'NoAns_total': 5945, 'best_exact': 72.95544512760044, 'best_exact_thresh': 0.0, 'best_f1': 76.28942043046025, 'best_f1_thresh': 0.0}
